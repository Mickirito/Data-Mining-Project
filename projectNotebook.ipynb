{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f117675e",
   "metadata": {},
   "source": [
    "# Feature Selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5de51dbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 features with the biggest impact on G 1 and there scores calculated with Univariate Selection\n",
      "     Features       Score\n",
      "14   failures  338.204484\n",
      "29   absences  164.040058\n",
      "6        Medu   37.555212\n",
      "15  schoolsup   37.158663\n",
      "0      school   35.794843\n",
      "8        Mjob   32.364700\n",
      "7        Fedu   28.700149\n",
      "27       Walc   25.999364\n",
      "13  studytime   25.425352\n",
      "26       Dalc   24.534230\n",
      "\n",
      "Mean Squared Error for predicting G 1 using Feature Selection with 10 features is 6.983089078386679\n",
      "\n",
      "The 10 features with the biggest impact on G 2 and there scores calculated with Univariate Selection\n",
      "     Features       Score\n",
      "29   absences  395.609383\n",
      "14   failures  333.055850\n",
      "6        Medu   40.843899\n",
      "15  schoolsup   34.047563\n",
      "0      school   31.761423\n",
      "7        Fedu   31.086546\n",
      "8        Mjob   29.590094\n",
      "27       Walc   26.748477\n",
      "3     address   25.822547\n",
      "26       Dalc   21.123821\n",
      "\n",
      "Mean Squared Error for predicting G 2 using Feature Selection with 10 features is 8.74762468807451\n",
      "\n",
      "The 10 features with the biggest impact on G 3 and there scores calculated with Univariate Selection\n",
      "     Features       Score\n",
      "29   absences  871.725890\n",
      "14   failures  374.745029\n",
      "15  schoolsup   38.716756\n",
      "6        Medu   38.266329\n",
      "0      school   37.998394\n",
      "27       Walc   35.684513\n",
      "26       Dalc   32.518849\n",
      "7        Fedu   30.259620\n",
      "8        Mjob   25.727454\n",
      "17       paid   21.794557\n",
      "\n",
      "Mean Squared Error for predicting G 3 using Feature Selection with 10 features is 12.12783560149358\n",
      "\n",
      "Mean Squared Error for predicting grades using Feature Selection with 10 features is 9.287183122651589\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "data_mat = pd.read_excel(\"data_mat.xlsx\")\n",
    "data_por = pd.read_excel(\"data_por.xlsx\")\n",
    "data = data_mat.append([data_por])\n",
    "\n",
    "y_G1 = data.iloc[:,30:31]    #target column G1\n",
    "y_G2 = data.iloc[:,31:32]    #target column G2\n",
    "y_G3 = data.iloc[:,32:33]    #target column G3\n",
    "X = data.drop(['G1', 'G2', 'G3'], axis = 1) #feature columns\n",
    "y = [y_G1,y_G2,y_G3]\n",
    "\n",
    "#Replace string variables with numbers\n",
    "#school\n",
    "school = {'GP': 0, 'MS': 1}\n",
    "X.school = [school[item] for item in X.school]\n",
    "#sex\n",
    "sex = {'M': 0, 'F': 1}\n",
    "X.sex = [sex[item] for item in X.sex]\n",
    "#address\n",
    "address = {'U': 0, 'R': 1}\n",
    "X.address = [address[item] for item in X.address]\n",
    "#famsize\n",
    "famsize = {'LE3': 0, 'GT3': 1}\n",
    "X.famsize = [famsize[item] for item in X.famsize]\n",
    "#Pstatus\n",
    "Pstatus = {'T': 0, 'A': 1}\n",
    "X.Pstatus = [Pstatus[item] for item in X.Pstatus]\n",
    "#Mjob\n",
    "Mjob = {'teacher': 0, 'health': 1, 'services': 2, 'at_home': 3, 'other': 4}\n",
    "X.Mjob = [Mjob[item] for item in X.Mjob]\n",
    "#Fjob\n",
    "Fjob = {'teacher': 0, 'health': 1, 'services': 2, 'at_home': 3, 'other': 4}\n",
    "X.Fjob = [Fjob[item] for item in X.Fjob]\n",
    "#reason\n",
    "reason = {'home': 0, 'reputation': 1, 'course': 2, 'other': 3}\n",
    "X.reason = [reason[item] for item in X.reason]\n",
    "#guardian\n",
    "guardian = {'mother': 0, 'father': 1, 'other': 2}\n",
    "X.guardian = [guardian[item] for item in X.guardian]\n",
    "#schoolsup\n",
    "schoolsup = {'no': 0, 'yes': 1}\n",
    "X.schoolsup = [schoolsup[item] for item in X.schoolsup]\n",
    "#famsup\n",
    "famsup = {'no': 0, 'yes': 1}\n",
    "X.famsup = [famsup[item] for item in X.famsup]\n",
    "#paid\n",
    "paid = {'no': 0, 'yes': 1}\n",
    "X.paid = [paid[item] for item in X.paid]\n",
    "#activities\n",
    "activities = {'no': 0, 'yes': 1}\n",
    "X.activities = [activities[item] for item in X.activities]\n",
    "#nursery\n",
    "nursery = {'no': 0, 'yes': 1}\n",
    "X.nursery = [nursery[item] for item in X.nursery]\n",
    "#higher\n",
    "higher = {'no': 0, 'yes': 1}\n",
    "X.higher = [higher[item] for item in X.higher]\n",
    "#internet\n",
    "internet = {'no': 0, 'yes': 1}\n",
    "X.internet = [internet[item] for item in X.internet]\n",
    "#romantic\n",
    "romantic = {'no': 0, 'yes': 1}\n",
    "X.romantic = [romantic[item] for item in X.romantic]\n",
    "\n",
    "total_error = 0.3 #keeps track of the total mean squared error\n",
    "for g in range(len(y)): #loops over all 3 periods\n",
    "    #Extract the 10 features with the biggest impact by applying Univariate Selection\n",
    "    features = SelectKBest(score_func=chi2, k=10)\n",
    "    fit = features.fit(X,y[g])\n",
    "    scores = pd.DataFrame(fit.scores_)\n",
    "    columns = pd.DataFrame(X.columns)\n",
    "    #Print the 10 features and their respective scores by concatenating them into a list\n",
    "    featureScores = pd.concat([columns,scores],axis=1)\n",
    "    featureScores.columns = ['Features','Score']  #naming the dataframe columns\n",
    "    print('The 10 features with the biggest impact on G',g+1 , 'and there scores calculated with Univariate Selection')\n",
    "    bestFeatures = featureScores.nlargest(10,'Score') #store the 10 best features\n",
    "    print(bestFeatures)\n",
    "    print()\n",
    "\n",
    "    selection = np.asarray(bestFeatures)[:,0] #list containing the names of the 10 selected features\n",
    "    allFeatures = np.asarray(X.columns) #list containing the names of all features\n",
    "\n",
    "    Xfiltered = X #copy X so we can filter away all the features that aren't selected without modifying the original\n",
    "\n",
    "    for i in range(len(allFeatures)): #loop over all features in X\n",
    "        selected = False\n",
    "        for j in range(len(selection)): #loop over all selected features\n",
    "            if allFeatures[i] == selection[j]: #if the current feature in X is in the list of selected features\n",
    "                selected = True #set selected to true\n",
    "        if selected == False: #if the feature is not selected\n",
    "            Xfiltered = Xfiltered.drop(columns = allFeatures[i]) #drop it\n",
    "\n",
    "    errors = 0 #keeps track of means squared error of the predicted grades for the current period\n",
    "    for i in range(0,100): #predict and calculate the mean squared error 100 times for more accuracy\n",
    "        X_train, X_test, y_train, y_test = train_test_split(Xfiltered,y[g], test_size=0.3) #split the data into test and train set\n",
    "        linear_regression = LinearRegression().fit(X_train, y_train) #fit the data into linear regression format\n",
    "        predictions = linear_regression.predict(X_test) #use the linear regression format to predict the grades\n",
    "        errors = errors + mean_squared_error(y_test, predictions) #calculate the mean squared error\n",
    "    total_error = total_error + errors #add error to total error\n",
    "    print('Mean Squared Error for predicting G', g+1, 'using Feature Selection with 10 features is', errors/100) #print the mean error of all 100 runs\n",
    "    print()\n",
    "print('Mean Squared Error for predicting grades using Feature Selection with 10 features is', total_error/300) #print the mean error of all runs of all grades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19e06c2",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08962678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error G 1 is 8.000756276465772 without modifing the data\n",
      "Error G 2 is 9.572744712904935 without modifing the data\n",
      "Error G 3 is 13.764134869106808 without modifing the data\n",
      "Total Error: 10.445878619492506\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "data_mat = pd.read_excel(\"data_mat.xlsx\")\n",
    "data_por = pd.read_excel(\"data_por.xlsx\")\n",
    "data = data_mat.append([data_por])\n",
    "\n",
    "y_G1 = data.iloc[:,30:31]    #target column Daily Alcohol Consumption\n",
    "y_G2 = data.iloc[:,31:32]    #target column Weekly Alcohol Consumption\n",
    "y_G3 = data.iloc[:,32:33]\n",
    "X = data.drop(['G1','G2','G3'], axis = 1) #feature columns\n",
    "y = [y_G1,y_G2,y_G3]\n",
    "\n",
    "\n",
    "#Replace string variables with numbers\n",
    "#school\n",
    "school = {'GP': 0, 'MS': 1}\n",
    "X.school = [school[item] for item in X.school]\n",
    "#sex\n",
    "sex = {'M': 0, 'F': 1}\n",
    "X.sex = [sex[item] for item in X.sex]\n",
    "#address\n",
    "address = {'U': 0, 'R': 1}\n",
    "X.address = [address[item] for item in X.address]\n",
    "#famsize\n",
    "famsize = {'LE3': 0, 'GT3': 1}\n",
    "X.famsize = [famsize[item] for item in X.famsize]\n",
    "#Pstatus\n",
    "Pstatus = {'T': 0, 'A': 1}\n",
    "X.Pstatus = [Pstatus[item] for item in X.Pstatus]\n",
    "#Mjob\n",
    "Mjob = {'teacher': 0, 'health': 1, 'services': 2, 'at_home': 3, 'other': 4}\n",
    "X.Mjob = [Mjob[item] for item in X.Mjob]\n",
    "#Fjob\n",
    "Fjob = {'teacher': 0, 'health': 1, 'services': 2, 'at_home': 3, 'other': 4}\n",
    "X.Fjob = [Fjob[item] for item in X.Fjob]\n",
    "#reason\n",
    "reason = {'home': 0, 'reputation': 1, 'course': 2, 'other': 3}\n",
    "X.reason = [reason[item] for item in X.reason]\n",
    "#guardian\n",
    "guardian = {'mother': 0, 'father': 1, 'other': 2}\n",
    "X.guardian = [guardian[item] for item in X.guardian]\n",
    "#schoolsup\n",
    "schoolsup = {'no': 0, 'yes': 1}\n",
    "X.schoolsup = [schoolsup[item] for item in X.schoolsup]\n",
    "#famsup\n",
    "famsup = {'no': 0, 'yes': 1}\n",
    "X.famsup = [famsup[item] for item in X.famsup]\n",
    "#paid\n",
    "paid = {'no': 0, 'yes': 1}\n",
    "X.paid = [paid[item] for item in X.paid]\n",
    "#activities\n",
    "activities = {'no': 0, 'yes': 1}\n",
    "X.activities = [activities[item] for item in X.activities]\n",
    "#nursery\n",
    "nursery = {'no': 0, 'yes': 1}\n",
    "X.nursery = [nursery[item] for item in X.nursery]\n",
    "#higher\n",
    "higher = {'no': 0, 'yes': 1}\n",
    "X.higher = [higher[item] for item in X.higher]\n",
    "#internet\n",
    "internet = {'no': 0, 'yes': 1}\n",
    "X.internet = [internet[item] for item in X.internet]\n",
    "#romantic\n",
    "romantic = {'no': 0, 'yes': 1}\n",
    "X.romantic = [romantic[item] for item in X.romantic]\n",
    "\n",
    "totalError = 0\n",
    "for g in range(len(y)):\n",
    "    error = 0\n",
    "    for i in range(0,100):\n",
    "        #Split the data into test and train data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y[g], test_size=0.2)\n",
    "        #Create a PCA so that the number of features are reduced to a certain amount.\n",
    "        pca = PCA(n_components = 10)\n",
    "        #Fit the data to the new amount of features.\n",
    "        X_train = pca.fit_transform(X_train)\n",
    "        X_test = pca.transform(X_test)\n",
    "        #Fit the data into a linear regression format\n",
    "        linear_regression = LinearRegression().fit(X_train, y_train)\n",
    "        #make the predictions\n",
    "        predictions = linear_regression.predict(X_test)\n",
    "        error += mean_squared_error(y_test, predictions)\n",
    "    print(\"Error G\",g+1, \"is\",(error/100),\"without modifing the data\")\n",
    "    totalError += error\n",
    "print (\"Total Error:\",totalError/300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
